# Mini-Spark: Motor de Procesamiento Distribuido (Batch DAG)

Proyecto desarrollado en **Go** para el curso de Principios de Sistemas Operativos. Implementa un motor distribuido maestro-esclavo capaz de ejecutar trabajos por lotes (Batch) definidos como Grafos AcÃ­clicos Dirigidos (DAGs).

## CaracterÃ­sticas Principales

Cumplimiento total de la **Ruta A** del proyecto:

* **Arquitectura Distribuida:** ComunicaciÃ³n HTTP/JSON entre Master y Workers.
* **Planificador DAG:** Soporte para etapas dependientes (Map -> Shuffle -> Reduce/Join).
* **Operadores Soportados:** `MAP`, `FILTER`, `FLAT_MAP`, `REDUCE_BY_KEY`, `JOIN`.
* **Tolerancia a Fallos:** DetecciÃ³n de workers caÃ­dos (Heartbeats), re-planificaciÃ³n automÃ¡tica de tareas perdidas y reintentos.
* **GestiÃ³n de Memoria:** ImplementaciÃ³n de **Spill-to-Disk** cuando la memoria del agregador se llena.
* **Shuffle Real:** Particionamiento por Hash y transferencia de datos entre workers vÃ­a HTTP.
* **Input Splitting:** Lectura eficiente de archivos compartidos sin duplicidad de datos.

## Requisitos

* **Go** 1.22 o superior.
* **Make** (para automatizaciÃ³n).
* Sistema operativo Linux/macOS (o WSL en Windows).

## Estructura del Proyecto

```text
mini-spark/
â”œâ”€â”€ cmd/
â”‚   â”œâ”€â”€ master/      # Entrypoint del Nodo Maestro
â”‚   â”œâ”€â”€ worker/      # Entrypoint del Nodo Trabajador
â”‚   â””â”€â”€ client/      # CLI para enviar trabajos
â”œâ”€â”€ internal/
â”‚   â”œâ”€â”€ common/      # Protocolos, Tipos (Task, Report) y Constantes
â”‚   â”œâ”€â”€ master/      # LÃ³gica del Scheduler, Registry y API
â”‚   â”œâ”€â”€ worker/      # LÃ³gica del Executor, Shuffle Server y Memory Manager
â”‚   â”œâ”€â”€ storage/     # Persistencia en memoria del estado del Job
â”‚   â””â”€â”€ udf/         # Funciones definidas por el usuario (Map/Reduce logic)
â”œâ”€â”€ jobs_specs/      # Archivos JSON con definiciones de Jobs (DAGs)
â”œâ”€â”€ data/inputs/     # Datos de entrada generados
â”œâ”€â”€ tools/           # Scripts auxiliares (Generador de datos)
â””â”€â”€ Makefile         # Script de automatizaciÃ³n
```


## Inicio RÃ¡pido (Demo)
Hemos incluido un Makefile para facilitar la ejecuciÃ³n del clÃºster y las demostraciones.

1. Generar Datos de Prueba
Genera datasets para WordCount, Join y un Benchmark de 1M de registros.

Bash

make gen-data
2. Arrancar el ClÃºster
Compila los binarios e inicia 1 Master y 2 Workers en segundo plano.

Bash

make run-cluster
Los logs se guardarÃ¡n en la carpeta logs/.

3. Ejecutar Trabajos
Demo 1: WordCount (ClÃ¡sico)

Bash

make demo-wordcount
Demo 2: Join de Tablas (Usuarios y Pedidos)

Bash

make demo-join
Este job realiza un cruce de datos relacionales distribuidos.

Demo 3: Benchmark (1 MillÃ³n de Registros)

Bash

make benchmark
4. Detener el ClÃºster
Mata todos los procesos del sistema.

Bash

make stop-cluster
## Pruebas de Tolerancia a Fallos (Chaos Monkey)
Para verificar la resiliencia del sistema:

Aumentar el tamaÃ±o de los datos o usar el benchmark (make benchmark).

Mientras el trabajo estÃ¡ en estado RUNNING, identificar el PID de un worker:

Bash

ps aux | grep worker
Matar el proceso:

Bash

kill -9 <PID_WORKER>
Observar en logs/master.log cÃ³mo el sistema detecta la falla, marca el worker como DOWN y reasigna las tareas pendientes al worker sobreviviente. El trabajo terminarÃ¡ exitosamente (SUCCEEDED).

ğŸ“Š Rendimiento
En pruebas locales con un dataset de 1,000,000 de registros (aprox 70MB) y 2 Workers:

Tiempo de ejecuciÃ³n: ~9 segundos.

Throughput: ~110,000 registros/segundo.

ğŸ“ Decisiones de DiseÃ±o (Sistemas Operativos)
Concurrencia: Uso de goroutines y canales para el manejo asÃ­ncrono de tareas y peticiones HTTP sin bloquear el hilo principal.

SincronizaciÃ³n: Uso de sync.Mutex y atomic para proteger estructuras compartidas (Registry, JobStore) ante condiciones de carrera.

I/O Eficiente: Uso de bufio.Scanner y bufio.Writer para minimizar las llamadas al sistema (Syscalls) durante la lectura/escritura de archivos grandes.

GestiÃ³n de Recursos: ImplementaciÃ³n de un Worker Pool (SemÃ¡foro) para limitar el nÃºmero de hilos concurrentes y evitar la saturaciÃ³n de CPU.