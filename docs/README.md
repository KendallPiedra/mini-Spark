
# Mini-Spark: Motor de Procesamiento Distribuido (Batch DAG)

Este proyecto implementa un motor de procesamiento distribuido Master-Worker desde cero, siguiendo la **Ruta A (Batch DAG)** del curso Principios de Sistemas Operativos.

## Requisitos y Dependencias

Para compilar y ejecutar el proyecto se requiere:

- **Go:** Versi贸n 1.22 o superior.
    
- **Make:** Utilizado para la automatizaci贸n de la compilaci贸n y la gesti贸n del cl煤ster.
    
- **Sistema Operativo:** Linux, macOS o Windows Subsystem for Linux (WSL).
    

## Preparativos e Instalaci贸n

### 1. Inicializaci贸n y Construcci贸n

El `Makefile` automatiza la compilaci贸n de todos los ejecutables necesarios (`master`, `worker`, `client`, `datagen`, y los binarios de prueba de caos).


```bash
# Compila todos los binarios y los coloca en la carpeta 'bin/'
make build
```

### 2. Generaci贸n de Datos de Prueba

El proyecto utiliza la herramienta `datagen` para crear los archivos de entrada (`.txt`, `.csv`) necesarios para las demostraciones.


```bash
# Ejecuta el binario datagen para llenar la carpeta ./data/inputs
make gen-data
```

**Nota:** Este paso crea archivos como `big_1m.txt` (1 mill贸n de registros) y `join_data.txt`.

---

##  Ejecuci贸n del Cl煤ster

Existen dos m茅todos principales para ejecutar el sistema: **Autom谩tico (Makefile)**, recomendado para demos, y **Manual (Terminales)**, 煤til para la depuraci贸n.

### A. Modo Autom谩tico (Makefile)

Utiliza `make` para iniciar y detener todos los componentes en segundo plano (`nohup`).

|**Comando**|**Descripci贸n**|
|---|---|
|`make run-cluster`|Inicia el **Master** y dos **Workers estables** (8081, 8082). Los logs se guardan en `./logs/`.|
|`make add-worker`|Inicia un Worker adicional en un puerto aleatorio (`8083`-`8099`).|
|`make stop-cluster`|Detiene todos los procesos de Master y Workers iniciados.|

### B. Modo Manual (3 Terminales)

Para una depuraci贸n m谩s detallada o control directo de los procesos:

1. **Terminal 1 (Master):**


```bash
./bin/master
```

2. **Terminal 2 (Worker 1):**

```bash
./bin/worker -port 8081
```

2. **Terminal 3 (Worker 2):**

```bash
./bin/worker -port 8082
```


---

## И Demostraciones y Pruebas

Los Jobs se definen en archivos JSON en la carpeta `./jobs_specs/`. El cliente (`./bin/client`) lee estas especificaciones y las env铆a al Master.

|**Comando**|**Descripci贸n**|**Flujo**|
|---|---|---|
|`make demo-wordcount`|Ejecuta el conteo de palabras sobre un dataset de prueba.|MAP $\to$ SHUFFLE $\to$ REDUCE|
|`make demo-join`|Ejecuta la uni贸n de dos colecciones (JOIN por clave).|MAP $\to$ SHUFFLE $\to$ JOIN|
|`make launch-chaos-job`|**Prueba de Tolerancia a Fallos**. Lanza un trabajo con UDFs lentas que requiere sabotaje manual.|LENTO MAP $\to$ SHUFFLE $\to$ REDUCE|

### Prueba de Tolerancia a Fallos (Chaos Monkey)

Para demostrar la resiliencia del sistema (replanificaci贸n de tareas):

1. **Iniciar el Modo Caos:**

```bash
make chaos-test
```

_El sistema se iniciar谩 con binarios de Worker LENTOS, y la consola mostrar谩 los PIDs del Worker A y B._

1. Sabotear (En otra Terminal):

Una vez que el cliente comience a enviar el trabajo lento (despu茅s del mensaje de instrucciones), mata el proceso del Worker 8081:

```bash
make kill-worker WORKER_PORT=8081
```

1. **Verificaci贸n:** El Master detectar谩 el fallo y reasignar谩 las tareas pendientes al Worker 8082, completando el trabajo exitosamente.
    

---

## Estructura de Datos (Inputs y Outputs)

La persistencia y el intercambio de datos se organizan en el directorio **`./data`** del proyecto:

- **`./data/inputs/`**: Contiene los archivos de entrada para los Jobs.
    
    - Ejemplos: `wordcount.txt`, `join_data.txt`, `big_1m.txt` (1 mill贸n de registros para el Benchmark).
    - Son consumidos por la etapa inicial MAP de cada Job.
        
- **`./data/outputs/`**: Es el destino final de los resultados.
    
    - El Master planifica la salida para esta carpeta, garantizando la persistencia de los resultados.
    - La ruta de los resultados es: `./data/outputs/[JOB_ID]/[STAGE_ID]_final_[TASK_ID]_out`.
    - El formato de los datos de salida es **JSON Lines (JSONL)**.
        
- **`./logs/`**: Almacena los archivos de log de cada proceso (`master.log`, `worker_8081.log`) cuando se ejecuta en modo `nohup` (Autom谩tico).
    
- **`./bin/`**: Almacena todos los ejecutables compilados (`MASTER_BIN`, `WORKER_BIN`, etc.).
    
- **`./jobs_specs/`**: Contiene los archivos JSON que definen el DAG (Grafos Ac铆clicos Dirigidos) y los UDFs (Funciones Definidas por el Usuario) de cada Job.